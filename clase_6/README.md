# ğŸ¥ Clase #6  
### ğŸ”§ Syphon (Mac), Raspberry + OpenCV, cables.gl y Kinect  

Durante la clase de hoy exploramos herramientas y librerÃ­as que integran **video, visiÃ³n por computador e interacciÃ³n en tiempo real**.  
La sesiÃ³n combinÃ³ entornos de desarrollo en **Mac** y **Raspberry Pi**, ademÃ¡s de ejercicios prÃ¡cticos con **Arduino** y **Processing**.  

---

### ğŸ§© Parte 1 â€” Syphon (Mac)  
Se revisÃ³ el flujo de trabajo con **Syphon**, un sistema de intercambio de video en tiempo real entre aplicaciones en **macOS**.  
Permite enviar y recibir frames de video entre entornos como **Processing**, **VDMX**, **MadMapper** o **TouchDesigner**, facilitando el desarrollo de visuales interactivos.  

ğŸ“¦ LibrerÃ­as revisadas:  
- [Syphon for Processing](https://github.com/Syphon/Processing)  
- Ejemplos de envÃ­o y recepciÃ³n de texturas entre ventanas y aplicaciones.  

---

### ğŸ§  Parte 2 â€” Raspberry Pi + OpenCV  
ConfiguraciÃ³n de entorno en **Raspberry Pi OS** para trabajar con **OpenCV** y visiÃ³n por computador.  
Se utilizÃ³ un entorno virtual con `venv` y la instalaciÃ³n del paquete extendido:  

```bash
sudo apt install python3-venv
python3 -m venv cvenv
source cvenv/bin/activate
pip install opencv-contrib-python
```

ğŸ” LibrerÃ­a: [opencv-contrib-python](https://pypi.org/project/opencv-contrib-python/)  
Esta versiÃ³n incluye mÃ³dulos avanzados para seguimiento, calibraciÃ³n y anÃ¡lisis de movimiento.  

---

### ğŸŒ Parte 3 â€” cables.gl  
IntroducciÃ³n a **[cables.gl](https://cables.gl)**, una plataforma online para composiciÃ³n visual basada en nodos.  
Se revisaron los **elementos bÃ¡sicos del entorno**, incluyendo:
- Panel de nodos y conexiones.  
- Inputs, Outputs y Operators.  
- CreaciÃ³n de animaciones simples y render en WebGL.  

---

### ğŸ•¹ï¸ Parte 4 â€” Kinect + Processing  
DemostraciÃ³n del uso del **sensor Kinect** para captura de profundidad y movimiento, aplicando el flujo de video como textura en Processing.  
Se revisÃ³ la integraciÃ³n con **Syphon** para compartir la salida con otros entornos visuales.  

ğŸ“š Se discutieron conceptos clave de:
- Nubes de puntos (point clouds).  
- Tracking de usuarios.  
- ComunicaciÃ³n entre software mediante protocolos Syphon/NDI.  

---

### âš¡ Parte 5 â€” Arduino + Processing  
Ejercicio final: **Control de opacidad mediante sensor de distancia**.  
Se conectÃ³ un **sensor SHARP** a **Arduino**, enviando datos analÃ³gicos a **Processing** por puerto serial.  
El valor del sensor fue mapeado para modificar dinÃ¡micamente la **opacidad de una forma o imagen**.  

ğŸ’¡ Conceptos aplicados:
- ComunicaciÃ³n **Serial**.  
- Mapeo de valores con `map()`.  
- SincronizaciÃ³n entre hardware y visuales digitales.  

---

ğŸ§¾ **Resumen de la clase:**  
- ğŸ’» IntegraciÃ³n de video con Syphon o NDI.  
- ğŸ§  ConfiguraciÃ³n de entorno Python + OpenCV en Raspberry.  
- ğŸŒ ExploraciÃ³n de cables.gl.  
- ğŸ® Captura con Kinect y envÃ­o de video en red.  
- ğŸ”§ Control de opacidad en Processing desde Arduino.
